apiVersion: v1
kind: Pod
metadata:
  name: nginx
  lables:
    app: nginx
    team: devops
spec:
  containers:
  - name: nginx
    image: nginx:1.14.3
    ports:
    - containerPort: 80
  - name: frontend
    image: httpd:1.14.2
    ports:
    - containerPort: 80
    env:
     - name: COLOR
       value: blue

*.yaml/yml


---

apiVersion: v1
kind: Deployment
metadata:                             // deployment template
  name: nginx-deployment
  labels:
    app: nginx
  namespace: app-1     // Independent compartments given to us for hosting applications
spec:
  replicas: 3
  selector:
    matchLabels:
      app: nginx
  template:                         //Pod Template
    metadata:
      name: nginx
      lables:
        app: nginx
    spec:
      containers:
        - name: nginx
          image: 'nginx:v1'
          ports:
            - containerPort: 80

namespace -- isolated environment given to application in Kubernetes setup

kubectl --> your interface command line
------

apiVersion: v1
kind: Service
metadata:
  labels:
    app: nginx
  name: nginx
  namespace: app-1
spec:
  ports:
      port: 80
      protocol: TCP
      targetPort: 80
  selector:
    app: nginx
  type: ClusterIP

----

Commands to connect to EKS
1. ADD adminstrator role to the ec2 machine that u are trying to connect.

2. aws configure and Create your AWS Access Keys.

3. aws eks update-kubeconfig --name my-eks-cluster --region us-east-1

--

For AWS Load balancer-:

Do apply this tag to all your AWS EKS subnets:
kubernetes.io/cluster/<your-eks-clustername> shared

example:
kubernetes.io/cluster/my-eks-cluster shared
kubernetes.io/role/elb 1

---

apiVersion: v1
kind: ConfigMap
metadata:
  name: example-redis-config
data:
  redis-config: |
    maxmemory 2mb
    maxmemory-policy allkeys-lru

alternative:
------

apiVersion: v1
kind: ConfigMap
metadata:
  name: special-config
  namespace: default
data:
  special.how: very   
  redis-config.maxmemory: 2mb
  redis-config.maxmemory-policy: allkeys 

---


configmapkeyRef:
envFrom:
volumes:
